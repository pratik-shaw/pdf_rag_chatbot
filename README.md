# ğŸ“š PDF RAG Chatbot - Level 1

A production-ready Retrieval-Augmented Generation (RAG) chatbot that enables intelligent question-answering on PDF documents using semantic search + OpenAI models.

Upload PDFs â†’ System processes + indexes them â†’ Ask questions â†’ Get context-aware answers with sources.

---

# ğŸš€ Features

## ğŸ” Core Capabilities
- Multi-PDF processing  
- Semantic similarity search (SentenceTransformers)
- Intelligent sentence-aware chunking  
- Persistent FAISS vector storage  
- GPT-powered answer generation  
- Source attribution with similarity scores  
- Confidence scoring  

## ğŸ’¡ User Experience
- Clean Streamlit web UI  
- Real-time progress and logs  
- Chat history with context  
- Session persistence  
- System status dashboard  

---

# ğŸ—ï¸ System Architecture

```
PDF RAG Chatbot
â”œâ”€â”€ RAG Core
â”‚   â”œâ”€â”€ PDF Processing
â”‚   â”œâ”€â”€ Text Chunking
â”‚   â”œâ”€â”€ Embeddings
â”‚   â”œâ”€â”€ Vector Store (FAISS)
â”‚   â””â”€â”€ Retrieval + Answering
â”‚
â””â”€â”€ Streamlit App
    â”œâ”€â”€ Upload UI
    â”œâ”€â”€ Processing Dashboard
    â””â”€â”€ Chat Interface
```

---

# ğŸ› ï¸ Tech Stack

| Component | Technology |
|----------|------------|
| Language | Python 3.8+ |
| UI | Streamlit |
| Embeddings | SentenceTransformers (MiniLM-L6-v2) |
| Vector DB | FAISS IndexFlatIP |
| PDF Parsing | PyPDF2 |
| LLM | OpenAI GPT Models |
| Env Config | python-dotenv |

---

# ğŸ“ Technical Specifications

### Embeddings
- Model: `all-MiniLM-L6-v2`
- Dim: 384  
- Similarity: Cosine (via Inner Product)

### Chunking
- Chunk size: `1000 chars`
- Overlap: `200 chars`
- Sentence-aware splitting

### Retrieval
- Top-K: 5 chunks
- Store: FAISS index + metadata `.pkl`

### Answer Generation
- Model: `gpt-3.5-turbo` (configurable)
- Temperature: `0.3`
- Max tokens: `500`

---

# ğŸ“ Project Structure

```
pdf-rag-chatbot/
â”œâ”€â”€ app.py
â”œâ”€â”€ rag_system.py
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ pdf_processor.py
â”‚   â”œâ”€â”€ text_splitter.py
â”‚   â””â”€â”€ embeddings.py
â”œâ”€â”€ vector_store/
â”‚   â”œâ”€â”€ faiss_index.index
â”‚   â””â”€â”€ chunks_metadata.pkl
â”œâ”€â”€ .env
â””â”€â”€ requirements.txt
```

---

# âš™ï¸ Installation & Setup

## 1ï¸âƒ£ Install Dependencies
```bash
pip install streamlit openai sentence-transformers faiss-cpu PyPDF2 python-dotenv numpy httpx
```

## 2ï¸âƒ£ Create `.env`
```
OPENAI_API_KEY=your_api_key_here
CHAT_MODEL=gpt-3.5-turbo
```

## 3ï¸âƒ£ Run App
```bash
streamlit run app.py
```

---

# ğŸ“– Usage Guide

## 1. Upload PDFs
- Click "Choose PDF files"
- Upload single or multiple PDFs
- Click **Process PDFs**

## 2. System Workflow
1. Extract text  
2. Split into chunks  
3. Generate embeddings  
4. Build FAISS index  
5. Save metadata  

## 3. Ask Questions
- Type your question  
- Click **Ask Question**  
- Get:  
  âœ” Answer  
  âœ” Sources (PDF + Page)  
  âœ” Similarity score  
  âœ” Confidence  

## 4. Manage System
- Load existing vector store  
- Clear data  
- Upload new documents  

---

# ğŸ”§ Configuration

### In `RAGSystem`:
```python
chunk_size=1000
chunk_overlap=200
top_k=5
```

### Embedding Model:
```python
model_name="all-MiniLM-L6-v2"
```

### OpenAI Model:
```
CHAT_MODEL=gpt-3.5-turbo
```

### Generation:
```python
temperature=0.3
max_tokens=500
```

---

# ğŸ›¡ï¸ Error Handling

- Invalid PDF â†’ gracefully skipped  
- API failure â†’ retry mechanism  
- No text â†’ shown to user  
- Corrupt FAISS â†’ auto rebuild option  

---

# ğŸ¯ Use Cases

### ğŸ‘©â€ğŸ“ Academia  
Search research papers  
Extract citations  

### âš– Legal  
Search clauses  
Extract definitions  

### ğŸ‘¨â€ğŸ’» Technical Docs  
Search APIs  
Extract code references  

### ğŸ“Š Business  
Analyze reports  
Extract data points  

---

# ğŸ”® Future Roadmap

### Level 2  
- Image + text multimodal  
- Structured table extraction  

### Level 3  
- Multi-tenant  
- Authentication  
- Batch ops  

### Level 4  
- Fine-tuned embeddings  
- Conversational memory  

---

# ğŸ“„ License
Open for educational and commercial use.

---

# ğŸ¤ Contact & Support
- Check troubleshooting section  
- Verify `.env`  
- Check logs in Streamlit terminal  

---

**Version:** 1.0.0  
**Status:** Production Ready  
